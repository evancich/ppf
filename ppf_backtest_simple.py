#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ppf_backtest_simple.py

Simple, disclosure-anchored, quarterly rebalanced backtest.

Inputs:
  - data/processed/transactions_enriched.csv (generated by ppf_pipeline.py)

Baseline Strategy (toy but auditable):
  - Use filing_date as the *earliest availability timestamp* (no transaction-date inference).
  - Filter to BUY only.
  - For each quarter, select top-N tickers by amount_max_usd (bucket max).
  - Equal-weight basket, rebalance at first trading day on/after quarter start.
  - Benchmark: SPY (auto_adjust=True).

Outputs:
  - outputs/ppf_backtest_history.csv
  - console metrics (Final Value, CAGR)

Caveats:
  - No costs/slippage.
  - Missing price history => ticker skipped for that quarter.
"""

from __future__ import annotations

import argparse
import logging
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Tuple

import pandas as pd

try:
    import yfinance as yf  # type: ignore
except Exception as e:  # pragma: no cover
    yf = None  # type: ignore

LOGGER = logging.getLogger("ppf_backtest")


def setup_logging(verbose: bool) -> None:
    LOGGER.setLevel(logging.DEBUG)
    LOGGER.handlers.clear()

    ch = logging.StreamHandler(sys.stdout)
    ch.setLevel(logging.DEBUG if verbose else logging.INFO)

    fmt = logging.Formatter(
        "%(asctime)sZ | %(levelname)-7s | %(name)s | %(message)s",
        datefmt="%Y-%m-%dT%H:%M:%S",
    )
    ch.setFormatter(fmt)
    LOGGER.addHandler(ch)


def first_trading_day_on_or_after(dates: pd.DatetimeIndex, ts: pd.Timestamp) -> pd.Timestamp | None:
    """Return the first index value >= ts, or None if not found."""
    if dates.empty:
        return None
    pos = dates.searchsorted(ts, side="left")
    if pos >= len(dates):
        return None
    return pd.Timestamp(dates[pos])


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser()
    p.add_argument("--tx-path", default="data/processed/transactions_enriched.csv")
    p.add_argument("--top-n", type=int, default=5)
    p.add_argument("--initial-capital", type=float, default=100000.0)
    p.add_argument("--benchmark", default="SPY")
    p.add_argument("--verbose", action="store_true")
    return p.parse_args()


def main() -> int:
    args = parse_args()
    setup_logging(args.verbose)

    if yf is None:
        LOGGER.error("yfinance is not installed in this venv. Install: pip install yfinance")
        return 2

    tx_path = Path(args.tx_path)
    if not tx_path.exists():
        LOGGER.error("Missing input CSV: %s", tx_path)
        return 2

    LOGGER.info("Loading transactions: %s", tx_path)
    tx = pd.read_csv(tx_path, parse_dates=["filing_date"])
    if tx.empty:
        LOGGER.error("transactions_enriched.csv is empty.")
        return 3

    # Baseline: BUY only
    tx = tx[tx["transaction_type"].astype(str).str.upper().str.strip() == "BUY"].copy()
    if tx.empty:
        LOGGER.error("No BUY transactions after filtering.")
        return 3

    # Ensure required columns exist
    for c in ["asset_id", "amount_max_usd", "filing_date"]:
        if c not in tx.columns:
            LOGGER.error("Missing required column: %s", c)
            return 4

    tx["quarter"] = tx["filing_date"].dt.to_period("Q")
    tx["amount_rank"] = tx.groupby("quarter")["amount_max_usd"].rank(method="first", ascending=False)

    selected = tx[tx["amount_rank"] <= int(args.top_n)].copy()
    quarter_portfolios = (
        selected.groupby("quarter")["asset_id"].apply(lambda x: list(pd.unique(x))).sort_index()
    )

    LOGGER.info("Quarterly portfolios: quarters=%d", len(quarter_portfolios))
    for q, tks in quarter_portfolios.items():
        LOGGER.info("%s -> %s", str(q), ", ".join(tks))

    all_tickers = sorted(set(selected["asset_id"].astype(str).unique().tolist() + [args.benchmark]))
    start_date = (tx["filing_date"].min() - pd.Timedelta(days=10)).date()
    end_date = datetime.now().date()

    LOGGER.info("Downloading prices: tickers=%d start=%s end=%s", len(all_tickers), start_date, end_date)
    px = yf.download(
        tickers=all_tickers,
        start=str(start_date),
        end=str(end_date),
        auto_adjust=True,
        progress=False,
        group_by="column",
    )

    if px.empty or "Close" not in px:
        LOGGER.error("No price data returned (expected 'Close' panel).")
        return 5

    prices = px["Close"].dropna(how="all")
    if prices.empty:
        LOGGER.error("Close price panel empty after dropna.")
        return 5

    dates = prices.index

    portfolio_value = float(args.initial_capital)
    benchmark_value = float(args.initial_capital)

    history_rows: List[Tuple[pd.Timestamp, float, float]] = []

    quarters = list(quarter_portfolios.index)
    for i, quarter in enumerate(quarters):
        tickers = quarter_portfolios.loc[quarter]

        q_start_ts = pd.Timestamp(quarter.start_time).tz_localize(None)
        rebalance_day = first_trading_day_on_or_after(dates, q_start_ts)
        if rebalance_day is None:
            LOGGER.warning("No trading day on/after %s (quarter=%s). Skipping.", q_start_ts, quarter)
            continue

        if i + 1 < len(quarters):
            next_q_start = pd.Timestamp(quarters[i + 1].start_time).tz_localize(None)
            q_end_day = first_trading_day_on_or_after(dates, next_q_start)
        else:
            q_end_day = None

        period = prices.loc[prices.index >= rebalance_day]
        if q_end_day is not None:
            period = period.loc[period.index < q_end_day]

        if period.empty:
            LOGGER.warning("Empty price slice quarter=%s start=%s", quarter, rebalance_day)
            continue

        valid = [t for t in tickers if t in period.columns and period[t].notna().any()]
        if not valid:
            LOGGER.warning("No valid tickers with prices quarter=%s tickers=%s", quarter, tickers)
            continue

        daily_rets = period[valid].pct_change().mean(axis=1).fillna(0.0)
        bench_rets = period[args.benchmark].pct_change().fillna(0.0)

        for d, r, br in zip(daily_rets.index, daily_rets.values, bench_rets.values):
            # IMPORTANT: benchmark compounds; do not reset each day
            portfolio_value *= (1.0 + float(r))
            benchmark_value *= (1.0 + float(br))
            history_rows.append((pd.Timestamp(d), portfolio_value, benchmark_value))

        LOGGER.info("Quarter %s rebalance=%s holdings=%d", quarter, rebalance_day.date(), len(valid))

    if not history_rows:
        LOGGER.error("No history rows produced. Likely: insufficient price coverage.")
        return 6

    hist = pd.DataFrame(history_rows, columns=["date", "portfolio_value", "benchmark_value"]).set_index("date")

    final_val = float(hist["portfolio_value"].iloc[-1])
    n_days = len(hist)
    cagr = (final_val / float(args.initial_capital)) ** (252.0 / float(n_days)) - 1.0

    LOGGER.info("Final Portfolio Value: %.2f", final_val)
    LOGGER.info("CAGR: %.2f %%", 100.0 * cagr)

    out_dir = Path("outputs")
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / "ppf_backtest_history.csv"
    hist.to_csv(out_path)
    LOGGER.info("Wrote: %s rows=%d", out_path, len(hist))

    # Optional plot (non-fatal)
    try:
        import matplotlib.pyplot as plt  # type: ignore
        plt.figure(figsize=(10, 6))
        plt.plot(hist.index, hist["portfolio_value"], label="Congress Strategy")
        plt.plot(hist.index, hist["benchmark_value"], label=str(args.benchmark))
        plt.legend()
        plt.title("Congress Disclosure Strategy vs Benchmark")
        plt.tight_layout()
        plt.show()
    except Exception:
        pass

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
